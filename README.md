# üìä Prueba T√©cnica ‚Äì Motor de Predicci√≥n de Ventas  
**Licorera "El Buen Gusto"**

Este proyecto implementa un sistema de an√°lisis y predicci√≥n de ventas utilizando Python y herramientas de c√≥digo abierto, con el objetivo de ayudar a la empresa a optimizar inventario, mejorar su gesti√≥n comercial y aumentar sus ingresos. La soluci√≥n est√° estructurada en tres fases: an√°lisis exploratorio, modelado predictivo y recomendaciones de negocio. Cada fase se entrega en un Jupyter Notebook independiente (.ipynb), acompa√±ado por un reporte ejecutivo dirigido a la gerencia.

---

## üìÅ Estructura del Proyecto

```
prueba-tecnica-el-buen-gusto/
‚îÇ
‚îú‚îÄ‚îÄ data/                     # Contiene 'ventas_licorera.csv' generado por script
‚îú‚îÄ‚îÄ notebooks/                # Notebooks para an√°lisis y modelos
‚îÇ   ‚îú‚îÄ‚îÄ analisis_exploratorio.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ modelado_predictivo.ipynb
‚îú‚îÄ‚îÄ scripts/                  # Script generador de datos
‚îÇ   ‚îî‚îÄ‚îÄ script_generar_dataset.py
‚îú‚îÄ‚îÄ reporte/                  # Reporte ejecutivo en PDF
‚îÇ   ‚îî‚îÄ‚îÄ reporte_ejecutivo.pdf
‚îú‚îÄ‚îÄ requirements.txt          # Dependencias del proyecto
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md
```

---

## üì¶ Librer√≠as / Paquetes Utilizados

| Paquete        | Versi√≥n  | Descripci√≥n                                               |
|----------------|----------|-----------------------------------------------------------|
| pandas         | 2.2.3    | Manipulaci√≥n de datos tabulares                           |
| numpy          | 2.2.4    | C√°lculos num√©ricos                                        |
| matplotlib     | 3.10.3   | Gr√°ficos y visualizaciones 2D                             |
| seaborn        | 0.13.2   | Gr√°ficos estad√≠sticos avanzados                           |
| plotly         | 6.1.2    | Visualizaci√≥n interactiva y gr√°fica avanzada              |
| scikit-learn   | 1.7.0    | Modelos de *machine learning*                             |
| xgboost        | 3.0.2    | Algoritmo de *boosting* para regresi√≥n y clasificaci√≥n    |
| lightgbm       | 4.6.0    | Algoritmo de *boosting* eficiente y r√°pido                |
| joblib         | 1.5.1    | Serializaci√≥n y almacenamiento de objetos                 |
| statsmodels    | 0.14.4   | Modelos estad√≠sticos y an√°lisis de series temporales      |
| prophet        | 1.1.7    | Modelado de series temporales con pron√≥stico (*forecasting*) |
| jupyter        | 1.1.1    | Ejecuci√≥n de *notebooks* interactivos                     |
| ipykernel      | 6.29.5   | Kernel para ejecutar Python dentro de Jupyter             |

Instalaci√≥n r√°pida:
```bash
pip install pandas numpy matplotlib seaborn plotly scikit-learn xgboost lightgbm statsmodels prophet joblib jupyter ipykernel

```

---

## ‚öôÔ∏è Instrucciones de Instalaci√≥n y Ejecuci√≥n

### üßæ Generar el archivo CSV

1. Abre la terminal y navega a la carpeta de scripts:
```bash
cd "C:\Users\kenit\Downloads\Prueba tecnica\scripts"
```

2. Ejecuta el script:
```bash
python script_generar_dataset.py
```
Esto generar√° el archivo `ventas_licorera.csv` en la carpeta `data/`.

Aseg√∫rate de que el script use la ruta correcta:
```python
filename = '../data/ventas_licorera.csv'
```

---

### üöÄ Opci√≥n R√°pida: Usar Kernel de Python Global

1. Desde la ra√≠z del proyecto, instala dependencias:
```bash
pip install pandas numpy matplotlib seaborn plotly scikit-learn xgboost lightgbm statsmodels prophet joblib jupyter ipykernel

```

2. O bien, usa el archivo `requirements.txt`:
```bash
pip install -r requirements.txt
```

3. Abre el archivo:
```
notebooks/analisis_exploratorio.ipynb o notebooks/modelado_predictivo.ipynb
```

4. Verifica que el kernel activo sea Python 3 (global).

5. Ejecuta con:
- `Shift + Enter`: ejecuta celda actual
- `Ejecutar todo`: desde el men√∫ de Jupyter o VS Code

---

### üíª Opci√≥n con Jupyter Notebook (desde navegador)

1. Instala las dependencias:
```bash
pip install pandas numpy matplotlib seaborn plotly scikit-learn xgboost lightgbm statsmodels prophet joblib jupyter ipykernel
```

2. Ejecuta Jupyter:
```bash
jupyter notebook
```

3. Se abrir√° en el navegador con la direcci√≥n http://localhost:8888/tree. Navega a:
```
notebooks/analisis_exploratorio.ipynb o notebooks/modelado_predictivo.ipynb
```

4. Verifica que el kernel diga: `Python 3 (ipykernel)`

5. Ejecuta celdas:
- `Shift + Enter`: celda actual
- `Ejecutar todo`: men√∫ superior

---

### ‚úÖ Opci√≥n Recomendable: Entorno Virtual

1. Crear entorno virtual:
```bash
python -m venv venv_buengusto
```

2. Activar entorno (en PowerShell):
```bash
.\venv_buengusto\Scripts\activate
```

3. Instalar dependencias:
```bash
pip install -r requirements.txt
```

4. En VS Code:
   - `Ctrl + Shift + P`
   - Selecciona: `Python: Select Interpreter`
   - Elige: `venv_buengusto/Scripts/python.exe`

5. Abre y ejecuta el notebook normalmente:
```
notebooks/analisis_exploratorio.ipynb o notebooks/modelado_predictivo.ipynb
```

6. Ejecuta celdas:
- `Shift + Enter`: ejecutar una celda
- `Ctrl + Enter`: ejecutar sin avanzar

---

## üß† Resumen del Enfoque

El proyecto desarroll√≥ un sistema de predicci√≥n de ventas para la licorer√≠a "El Buen Gusto" utilizando un enfoque h√≠brido que combina an√°lisis exploratorio avanzado (EDA) y modelado predictivo. Se prioriz√≥ la identificaci√≥n de patrones clave como estacionalidad, impacto de promociones y variables externas (clima, ubicaci√≥n de sucursales). Para el modelado, se implementaron y compararon tres enfoques: un modelo SARIMA para an√°lisis puramente temporal, XGBoost para capturar relaciones no lineales entre m√∫ltiples predictores, y un ensemble stacking que combin√≥ Random Forest con regresi√≥n lineal. El modelo final (XGBoost optimizado) logr√≥ un MAE de $41.14 diarios (8.7% del volumen promedio), destacando como variables cr√≠ticas las promociones, d√≠as festivos y temperatura.

La soluci√≥n se dise√±√≥ para ser accionable en el negocio, generando recomendaciones como paquetes estrat√©gicos y ajustes de inventario basados en pron√≥sticos clim√°ticos. El proyecto incluy√≥ limpieza de datos (20% registros de clientes incompletos), feature engineering y validaci√≥n cruzada temporal para garantizar robustez. El modelo explica la variabilidad en ventas; se intregr√≥ visualizaciones interactivos para visualizar tendencias y escenarios clave que indica las indicaciones de la prueba t√©cnica, permitiendo a la gerencia tomar decisiones con base en datos.

---



